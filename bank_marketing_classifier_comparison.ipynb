{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this assignment is derived from a series of telemarketing campaigns conducted by a Portuguese banking institution. These campaigns aimed to promote term deposit subscriptions to existing or potential clients via phone calls.\n",
    "\n",
    "As stated in the supporting paper by Moro et al. (2014), titled “A Data-Driven Approach to Predict the Success of Bank Telemarketing”, the data captures the outcomes of 17 different marketing campaigns carried out between May 2008 and November 2010.\n",
    "\n",
    "Each row in the dataset corresponds to a unique client contact during one of these campaigns. Various attributes related to the client’s personal information, contact timing, previous interactions, and economic indicators are included, along with the binary target variable y, which indicates whether the client subscribed to a term deposit (“yes” or “no”).\n",
    "\n",
    "This rich dataset allows us to explore the effectiveness of these marketing campaigns and apply machine learning models to predict campaign success based on the available features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t-\tNo explicit NaN values were found in the dataset.\n",
    "\t-\tseveral categorical features use \"unknown\" to represent missing or ambiguous information, including:\n",
    "\t\t•\tjob, marital, education, default, housing, and loan\t\n",
    "\t-\tThe duration column is not usable for real-time prediction, since it reflects post-call information and leaks the target. We might drop this column during preprocessing.\n",
    "\t-\tCategorical features will have label encoding or one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             41188 non-null  int64  \n",
      " 1   job             41188 non-null  object \n",
      " 2   marital         41188 non-null  object \n",
      " 3   education       41188 non-null  object \n",
      " 4   default         41188 non-null  object \n",
      " 5   housing         41188 non-null  object \n",
      " 6   loan            41188 non-null  object \n",
      " 7   contact         41188 non-null  object \n",
      " 8   month           41188 non-null  object \n",
      " 9   day_of_week     41188 non-null  object \n",
      " 10  duration        41188 non-null  int64  \n",
      " 11  campaign        41188 non-null  int64  \n",
      " 12  pdays           41188 non-null  int64  \n",
      " 13  previous        41188 non-null  int64  \n",
      " 14  poutcome        41188 non-null  object \n",
      " 15  emp.var.rate    41188 non-null  float64\n",
      " 16  cons.price.idx  41188 non-null  float64\n",
      " 17  cons.conf.idx   41188 non-null  float64\n",
      " 18  euribor3m       41188 non-null  float64\n",
      " 19  nr.employed     41188 non-null  float64\n",
      " 20  y               41188 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The business objective of this task is to predict whether a client will subscribe to a term deposit following a telemarketing campaign. This prediction will be based on various client attributes (e.g., age, job, education), previous interactions, and economic indicators.\n",
    "\n",
    "By accurately predicting campaign outcomes, the bank can,improve the efficiency of future marketing efforts, Prioritize leads that are more likely to convert\n",
    "\n",
    "The ultimate goal is to support the bank’s marketing team with data-driven insights that help increase the success rate of term deposit subscriptions while minimizing cost and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'duration' as it's not usable for realistic modeling\n",
    "df = df.drop('duration', axis=1)\n",
    "\n",
    "# Map the target column 'y': 'yes' -> 1, 'no' -> 0\n",
    "df['y'] = df['y'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical features\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (41188, 52)\n",
      "Target shape: (41188,)\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y (target)\n",
    "X = df_encoded.drop('y', axis=1)\n",
    "y = df_encoded['y']\n",
    "\n",
    "# Preview the shape of final data\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature set: (32950, 52)\n",
      "Test feature set: (8238, 52)\n",
      "Training target set: (32950,)\n",
      "Test target set: (8238,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training feature set: {X_train.shape}\")\n",
    "print(f\"Test feature set: {X_test.shape}\")\n",
    "print(f\"Training target set: {y_train.shape}\")\n",
    "print(f\"Test target set: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution in training set:\n",
      "y\n",
      "0    0.887344\n",
      "1    0.112656\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target distribution in test set:\n",
      "y\n",
      "0    0.887351\n",
      "1    0.112649\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Target distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTarget distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent class (baseline prediction): 0\n"
     ]
    }
   ],
   "source": [
    "# Most frequent class in y_train\n",
    "baseline_class = y_train.mode()[0]\n",
    "print(f\"Most frequent class (baseline prediction): {baseline_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline prediction: always predict the majority class\n",
    "y_pred_baseline = [baseline_class] * len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.8874\n",
      "\n",
      "Classification Report for Baseline Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      7310\n",
      "           1       0.00      0.00      0.00       928\n",
      "\n",
      "    accuracy                           0.89      8238\n",
      "   macro avg       0.44      0.50      0.47      8238\n",
      "weighted avg       0.79      0.89      0.83      8238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Baseline accuracy\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.4f}\")\n",
    "\n",
    "# Baseline classification report\n",
    "print(\"\\nClassification Report for Baseline Model:\")\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "logreg = LogisticRegression(max_iter=10000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9020\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      7310\n",
      "           1       0.70      0.23      0.34       928\n",
      "\n",
      "    accuracy                           0.90      8238\n",
      "   macro avg       0.81      0.61      0.64      8238\n",
      "weighted avg       0.89      0.90      0.88      8238\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7222   88]\n",
      " [ 719  209]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Accuracy\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f\"Logistic Regression Accuracy: {logreg_accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report for Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Train Time: 0.0127 seconds\n",
      "KNN Train Accuracy: 0.9122\n",
      "KNN Test Accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n",
    "# Initialize the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "knn.fit(X_train, y_train)\n",
    "train_time_knn = time.time() - start_time\n",
    "\n",
    "# Calculate accuracies\n",
    "train_acc_knn = knn.score(X_train, y_train)\n",
    "test_acc_knn = knn.score(X_test, y_test)\n",
    "\n",
    "# Show results\n",
    "print(f\"KNN Train Time: {train_time_knn:.4f} seconds\")\n",
    "print(f\"KNN Train Accuracy: {train_acc_knn:.4f}\")\n",
    "print(f\"KNN Test Accuracy: {test_acc_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Train Time: 0.1181 seconds\n",
      "Decision Tree Train Accuracy: 0.9954\n",
      "Decision Tree Test Accuracy: 0.8403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import time\n",
    "\n",
    "# Initialize the model\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "dtree.fit(X_train, y_train)\n",
    "train_time_dtree = time.time() - start_time\n",
    "\n",
    "# Calculate accuracies\n",
    "train_acc_dtree = dtree.score(X_train, y_train)\n",
    "test_acc_dtree = dtree.score(X_test, y_test)\n",
    "\n",
    "# Show results\n",
    "print(f\"Decision Tree Train Time: {train_time_dtree:.4f} seconds\")\n",
    "print(f\"Decision Tree Train Accuracy: {train_acc_dtree:.4f}\")\n",
    "print(f\"Decision Tree Test Accuracy: {test_acc_dtree:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Time: 6.3299 seconds\n",
      "SVM Train Accuracy: 0.8975\n",
      "SVM Test Accuracy: 0.8977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "# Initialize the model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Record training time\n",
    "start_time = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "train_time_svm = time.time() - start_time\n",
    "\n",
    "# Calculate accuracies\n",
    "train_acc_svm = svm.score(X_train, y_train)\n",
    "test_acc_svm = svm.score(X_test, y_test)\n",
    "\n",
    "# Show results\n",
    "print(f\"SVM Train Time: {train_time_svm:.4f} seconds\")\n",
    "print(f\"SVM Train Accuracy: {train_acc_svm:.4f}\")\n",
    "print(f\"SVM Test Accuracy: {test_acc_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "| KNN    |   0.0127 |0.9122     | 0.8934    |\n",
    "| Decision Tree    |   0.1181 |0.9954     |0.8403   |\n",
    "| SVM    |   6.3299 |0.8975   |0.8977   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'n_neighbors': 5}\n",
      "Best F1 Score (CV): 0.3622981700139366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_knn = {'n_neighbors': list(range(3, 16))}\n",
    "\n",
    "# Grid search\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best params and score\n",
    "print(\"Best parameters for KNN:\", grid_knn.best_params_)\n",
    "print(\"Best F1 Score (CV):\", grid_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Decision Tree: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Best F1 Score (CV): 0.3690642005255639\n"
     ]
    }
   ],
   "source": [
    "param_grid_tree = {\n",
    "    'max_depth': [3, 5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_tree, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Decision Tree:\", grid_tree.best_params_)\n",
    "print(\"Best F1 Score (CV):\", grid_tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on Test Set (Best Decision Tree): 0.3994232155731795\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Pick best model (example: tuned Decision Tree)\n",
    "best_tree = grid_tree.best_estimator_\n",
    "y_pred_best_tree = best_tree.predict(X_test)\n",
    "\n",
    "print(\"F1 Score on Test Set (Best Decision Tree):\", f1_score(y_test, y_pred_best_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Logistic Regression Accuracy: 0.8297\n",
      "Balanced Logistic Regression F1 Score: 0.4593\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      7310\n",
      "           1       0.36      0.64      0.46       928\n",
      "\n",
      "    accuracy                           0.83      8238\n",
      "   macro avg       0.65      0.75      0.68      8238\n",
      "weighted avg       0.88      0.83      0.85      8238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression with class_weight='balanced'\n",
    "logreg_balanced = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "logreg_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_logreg_balanced = logreg_balanced.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "print(f\"Balanced Logistic Regression Accuracy: {accuracy_score(y_test, y_pred_logreg_balanced):.4f}\")\n",
    "print(f\"Balanced Logistic Regression F1 Score: {f1_score(y_test, y_pred_logreg_balanced):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_logreg_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model F1 Score: 0.0\n",
      "Logistic Regression (Original) F1 Score: 0.34\n",
      "Logistic Regression (Balanced) F1 Score: 0.4593\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1_baseline = 0.00\n",
    "f1_original = 0.34  \n",
    "f1_balanced = f1_score(y_test, y_pred_logreg_balanced)\n",
    "\n",
    "print(f\"Baseline Model F1 Score: {f1_baseline}\")\n",
    "print(f\"Logistic Regression (Original) F1 Score: {f1_original}\")\n",
    "print(f\"Logistic Regression (Balanced) F1 Score: {f1_balanced:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To improve our model’s performance and better capture the minority class (`yes` for term deposit), we explored several enhancements:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Hyperparameter Tuning\n",
    "We used `GridSearchCV` to tune:\n",
    "- **KNN**: Optimal number of neighbors\n",
    "- **Decision Tree**: Best depth and split configuration\n",
    "- **SVM**: Regularization (`C`) and kernel choice\n",
    "\n",
    "Models Improved especially the **Decision Tree** and **SVM** models.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Addressing Class Imbalance\n",
    "The dataset is highly imbalanced, with a majority of clients not subscribing to a term deposit.\n",
    "\n",
    "To address this:\n",
    "- We retrained **Logistic Regression** using `class_weight='balanced'`\n",
    "- This gave significant gains in **F1-score** (a better measure of performance in imbalanced classification)\n",
    "\n",
    "| Model                        | F1 Score |\n",
    "|-----------------------------|----------|\n",
    "| Baseline Model              | 0.00     |\n",
    "| Logistic Regression (Default) | 0.34     |\n",
    "| Logistic Regression (Balanced) | 0.4593 |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Evaluation Metric\n",
    "\n",
    "- **F1-score**: precision\n",
    "- **Classification Report**: To understand class performance\n",
    "- **Confusion Matrix**: To track false negatives, which are especially important in this case\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Recommendation\n",
    "\n",
    "Based on our results, we recommend:\n",
    "\n",
    "- Using **Logistic Regression with class weighting** or a **tuned SVM** as the production model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
